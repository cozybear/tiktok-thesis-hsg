{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tinAJi4brr_O"
      },
      "outputs": [],
      "source": [
        "!pip install catboost\n",
        "!pip install lightgbm\n",
        "!pip install shap\n",
        "!pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TzkzTpY0AZ1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import six\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import keras\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras import Input, layers, Model\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "import shap\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg5-oe8H6S3R"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLh45NXi5PRy"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.dpi'] = 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwSwCraWl6UB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIw4fZLyRNjI"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN_aAbrnVUdu"
      },
      "outputs": [],
      "source": [
        "#helper functions\n",
        "def adjusted_r2(y_test, y_pred, n_predictors):\n",
        "    r2 = r2_score(y_test, y_pred)  \n",
        "    adj_r2 = 1-(1-r2)*(len(y_test)-1)/(len(y_test)-n_predictors-1) \n",
        "    return adj_r2\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error(y_pred, y_true): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8fnWgYNevvF"
      },
      "outputs": [],
      "source": [
        "# Create dataset from multiple .tfrecord files\n",
        "train =                  [\"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00000-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00001-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00002-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00003-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00004-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00005-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00006-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00007-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00008-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00009-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00010-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00011-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00012-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00013-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00014-of-00016\",\n",
        "                          \"/content/drive/MyDrive/Celeb_A/celeb_a-train.tfrecord-00015-of-00016\",\n",
        "                          \n",
        "                          ]\n",
        "val = [\"/content/drive/MyDrive/Celeb_A/celeb_a-validation.tfrecord-00000-of-00002\",\n",
        "        \"/content/drive/MyDrive/Celeb_A/celeb_a-validation.tfrecord-00001-of-00002\"]\n",
        "\n",
        "test = [\"/content/drive/MyDrive/Celeb_A/celeb_a-test.tfrecord-00000-of-00002\",\n",
        "        \"/content/drive/MyDrive/Celeb_A/celeb_a-test.tfrecord-00001-of-00002\"]\n",
        "\n",
        "\n",
        "celeba_train = tf.data.TFRecordDataset(train)\n",
        "celeba_val = tf.data.TFRecordDataset(val)\n",
        "celeba_test = tf.data.TFRecordDataset(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAtcJii67sgW"
      },
      "outputs": [],
      "source": [
        "ATTRIBUTES = [\n",
        "    '5_o_Clock_Shadow',\n",
        "    'Arched_Eyebrows',\n",
        "    'Attractive',\n",
        "    'Bags_Under_Eyes',\n",
        "    'Bald',\n",
        "    'Bangs',\n",
        "    'Big_Lips',\n",
        "    'Big_Nose',\n",
        "    'Black_Hair',\n",
        "    'Blond_Hair',\n",
        "    'Blurry',\n",
        "    'Brown_Hair',\n",
        "    'Bushy_Eyebrows',\n",
        "    'Chubby',\n",
        "    'Double_Chin',\n",
        "    'Eyeglasses',\n",
        "    'Goatee',\n",
        "    'Gray_Hair',\n",
        "    'Heavy_Makeup',\n",
        "    'High_Cheekbones',\n",
        "    'Male',\n",
        "    'Mouth_Slightly_Open',\n",
        "    'Mustache',\n",
        "    'Narrow_Eyes',\n",
        "    'No_Beard',\n",
        "    'Oval_Face',\n",
        "    'Pale_Skin',\n",
        "    'Pointy_Nose',\n",
        "    'Receding_Hairline',\n",
        "    'Rosy_Cheeks',\n",
        "    'Sideburns',\n",
        "    'Smiling',\n",
        "    'Straight_Hair',\n",
        "    'Wavy_Hair',\n",
        "    'Wearing_Earrings',\n",
        "    'Wearing_Hat',\n",
        "    'Wearing_Lipstick',\n",
        "    'Wearing_Necklace',\n",
        "    'Wearing_Necktie',\n",
        "    'Young']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV1xJbfJ0JPe"
      },
      "outputs": [],
      "source": [
        "def _parse_function(example_proto):\n",
        "    feature_description= {\n",
        "\n",
        "              'attributes/5_o_Clock_Shadow': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Arched_Eyebrows': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Attractive': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Bags_Under_Eyes': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Bald': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Bangs': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Big_Lips': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Big_Nose': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Black_Hair': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Blond_Hair': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Blurry': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Brown_Hair': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Bushy_Eyebrows': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Chubby': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Double_Chin': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Eyeglasses': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Goatee': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Gray_Hair': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Heavy_Makeup': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/High_Cheekbones': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Male': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Mouth_Slightly_Open': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Mustache': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Narrow_Eyes': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/No_Beard': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Oval_Face': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Pale_Skin': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Pointy_Nose': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Receding_Hairline': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Rosy_Cheeks': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Sideburns': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Smiling': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Straight_Hair': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Wavy_Hair': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Wearing_Earrings': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Wearing_Hat': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Wearing_Lipstick': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Wearing_Necklace': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Wearing_Necktie': tf.io.FixedLenFeature((1,), tf.int64),\n",
        "              'attributes/Young': tf.io.FixedLenFeature((1,), tf.int64),           \n",
        "              \"image\": tf.io.FixedLenFeature((), tf.string)\n",
        "    }\n",
        "            \n",
        "    data = tf.io.parse_single_example(example_proto, feature_description)\n",
        "    image = data['image']\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "\n",
        "    attributes = {name: data[f'attributes/{name}']for name in ATTRIBUTES}\n",
        "\n",
        "    return {'image': image, 'attributes': attributes}\n",
        "\n",
        "celeba_train = celeba_train.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "celeba_val = celeba_val.map(_parse_function)\n",
        "celeba_test = celeba_test.map(_parse_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBe2uqh40MPb"
      },
      "outputs": [],
      "source": [
        "for e in celeba_train.take(1):\n",
        "    pass\n",
        "    plt.imshow(e['image'].numpy())\n",
        "    tf.print(e['attributes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDwvSkRPiAvc"
      },
      "outputs": [],
      "source": [
        "def process(e):\n",
        "    image = e['image']\n",
        "    image = tf.image.resize_with_pad(image, 128, 128)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    \n",
        "    atts = []\n",
        "    for c in ATTRIBUTES:\n",
        "        atts.append(tf.cast(e['attributes'][c], tf.float32))\n",
        "    atts = tf.stack(atts)\n",
        "    \n",
        "    return image, atts\n",
        "\n",
        "ds_train = celeba_train.map(process).shuffle(10000).batch(64, drop_remainder=True)\n",
        "ds_val = celeba_val.map(process).batch(64, drop_remainder=True)\n",
        "ds_test = celeba_test.map(process).batch(64, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-XvBIMs0WSa"
      },
      "outputs": [],
      "source": [
        "class FaceAttributeModel(tf.keras.Model):\n",
        "    def __init__(self, dropout_rate=0.0, units=32, backbone=\"vgg16\", n_layers=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.backbone = backbone\n",
        "        self.n_layers = n_layers\n",
        "        self.units = units\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "        if self.backbone == \"vgg16\":\n",
        "          self.vgg = tf.keras.applications.VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(128, 128, 3),\n",
        "                  pooling='avg')\n",
        "          \n",
        "\n",
        "          self.vgg.trainable=False\n",
        "          \n",
        "\n",
        "          self.base = tf.keras.models.Sequential()\n",
        "          self.base.add(self.vgg)\n",
        "          self.base.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if self.backbone == \"resnet50\":\n",
        "          self.resnet = tf.keras.applications.ResNet50V2(\n",
        "                  weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(128, 128, 3),\n",
        "                  pooling='avg')\n",
        "\n",
        "        \n",
        "          self.resnet.trainable=False\n",
        "          \n",
        "\n",
        "          self.base = tf.keras.models.Sequential()\n",
        "          self.base.add(self.resnet)\n",
        "          self.base.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "        \n",
        "\n",
        "        #fully connected layer\n",
        "        self.dnn = tf.keras.models.Sequential()\n",
        "\n",
        "        for l in range(n_layers):\n",
        "          layer = tf.keras.models.Sequential()\n",
        "          layer.add(tf.keras.layers.Dense(units))\n",
        "          layer.add(tf.keras.layers.Activation('relu'))\n",
        "          self.dnn.add(layer)\n",
        "\n",
        "        # binary classification output layer\n",
        "        self.dnn.add(tf.keras.layers.Dense(len(ATTRIBUTES)))\n",
        "        self.dnn.add(tf.keras.layers.Activation('sigmoid'))\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def call(self, inputs, training=False):\n",
        "        run = inputs\n",
        "       \n",
        "        run = self.base(run, training=False)\n",
        "        run = self.dnn(run)\n",
        "\n",
        "        return run\n",
        "\n",
        "    def model(self):\n",
        "        img = Input(shape=(128,128,3))\n",
        "\n",
        "        return Model(inputs=img, outputs=self.call(img))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T5-apg2TPXQ"
      },
      "source": [
        "#Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCH0xLTOdHY8"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "  hp_units = hp.Choice('units', values=[32, 64])\n",
        "  hp_dropout_rate = hp.Choice('dropout_rate', values = [0.0, 0.2, 0.3])\n",
        "  hp_backbone = hp.Choice('backbone', values = ['vgg16', 'resnet50'])\n",
        "  hp_layers = hp.Choice('layers', values = [1, 2])\n",
        "\n",
        "  model = FaceAttributeModel(dropout_rate=hp_dropout_rate, units=hp_units, backbone=hp_backbone, n_layers=hp_layers)\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[0.001, 0.0005, 0.0001, 0.00005])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics=[tf.keras.metrics.Recall(thresholds=0.5), \n",
        "                       tf.keras.metrics.Precision(thresholds=0),\n",
        "                       tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX7g6xkf7hiq"
      },
      "outputs": [],
      "source": [
        "# Prepare a directory to store all the checkpoints.\n",
        "tuner_dir = \"/content/drive/MyDrive/tiktok_model/tuner_attributes\"\n",
        "\n",
        "if not os.path.exists(tuner_dir):\n",
        "    os.makedirs(tuner_dir)\n",
        "\n",
        "tuner = kt.Hyperband(build_model,\n",
        "                     objective='val_loss',\n",
        "                     max_epochs=80,\n",
        "                     factor=3,\n",
        "                     overwrite=True,\n",
        "                     directory=tuner_dir,\n",
        "                     max_consecutive_failed_trials=10,\n",
        "                     project_name='celeba_binary_classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXnRDoWU76w7"
      },
      "outputs": [],
      "source": [
        "#early stopping\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa_H61qU793t"
      },
      "outputs": [],
      "source": [
        "#perform hyperparmeter search\n",
        "tuner.search(x=ds_train, validation_data=ds_val, epochs=40, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAXxbsmUToq_"
      },
      "source": [
        "#Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbdT-F2M0Yl-"
      },
      "outputs": [],
      "source": [
        "#init with optimal hyperparameters\n",
        "model = FaceAttributeModel(dropout_rate=0.0, units=64, backbone=\"vgg16\", n_layers=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot model structure\n",
        "tf.keras.utils.plot_model(\n",
        "    model.model(),\n",
        "    show_shapes=True,\n",
        "    show_dtype=True,\n",
        "    show_layer_names=False,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=True,\n",
        "    dpi=200,\n",
        "    layer_range=None,\n",
        "    show_layer_activations=True,\n",
        ")"
      ],
      "metadata": {
        "id": "_BCpBxgpYULn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE3mx_-hXwK-"
      },
      "outputs": [],
      "source": [
        "#compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              metrics=[tf.keras.metrics.Recall(), \n",
        "                       tf.keras.metrics.Precision(),\n",
        "                       tf.keras.metrics.BinaryAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEuKTOGyFB0w"
      },
      "outputs": [],
      "source": [
        "# Prepare a directory to store all the checkpoints.\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Celeb_A_vgg/ckpt\"\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        # Path where to save the model\n",
        "        # The two parameters below mean that we will overwrite\n",
        "        # the current checkpoint if and only if\n",
        "        # the `val_loss` score has improved.\n",
        "        # The saved model name will include the current epoch.\n",
        "        filepath=\"/content/drive/MyDrive/Celeb_A_vgg/ckpt/CelebaModel_vgg{epoch}\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "# Prepare a directory to store all the logs.\n",
        "log_dir = \"/content/drive/MyDrive/Celeb_A/logs\"\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "  \n",
        "# Prepare a directory to store plots.\n",
        "plot_dir = \"/content/drive/MyDrive/Celeb_A/plots\"\n",
        "if not os.path.exists(plot_dir):\n",
        "    os.makedirs(plot_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXx3VeoT0acD"
      },
      "outputs": [],
      "source": [
        "history = model.fit(ds_train, epochs=60, callbacks=[model_checkpoint_callback], validation_data=ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ucmCiQavoFI"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4touPSpYQEMI"
      },
      "outputs": [],
      "source": [
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = '/content/drive/MyDrive/Celeb_A/logs/history_resnet.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BwH3NljC9FX"
      },
      "outputs": [],
      "source": [
        "#plot model loss\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(loss)\n",
        "plt.plot(val_loss)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.savefig(\"train_val_loss_vgg\", dpi=400, bbox_inches=\"tight\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall = history.history['val_recall']\n",
        "precision = history.history['val_precision']\n",
        "binary_accuracy = history.history['val_binary_accuracy']"
      ],
      "metadata": {
        "id": "s_Iu71WZQzMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP_i1i-ZYInO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(recall, label='Recall')\n",
        "plt.plot(precision, label='Precision')\n",
        "plt.plot(binary_accuracy, label='Binary Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.ylabel('Value')\n",
        "#plt.ylim(0, 1)\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1qRPwS0rvcr"
      },
      "outputs": [],
      "source": [
        "#alterantively load model from file \n",
        "model = keras.models.load_model('/content/drive/MyDrive/Celeb_A_vgg/ckpt/CelebaModel_vgg59')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation"
      ],
      "metadata": {
        "id": "8Y-pnfM8-0kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1CGMQwZ0cr2"
      },
      "outputs": [],
      "source": [
        "#Evaluation on test set\n",
        "labels = []\n",
        "preds = []\n",
        "for e, l in ds_test:\n",
        "    labels.extend(l.numpy())\n",
        "    preds.extend(model.predict(e, verbose=False))\n",
        "\n",
        "\n",
        "labels = np.array(labels)\n",
        "preds = np.array(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSLiGkWp0e3o"
      },
      "outputs": [],
      "source": [
        "#Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores\n",
        "for i, a in enumerate(ATTRIBUTES):\n",
        "    print('%s: %.5f' % (a, roc_auc_score(labels[:, i], preds[:, i])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPaBQPgLc8gj"
      },
      "outputs": [],
      "source": [
        "labels = labels[:, :, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwDq5J2_Bz1k"
      },
      "outputs": [],
      "source": [
        "#F1-scores\n",
        "for i, a in enumerate(ATTRIBUTES):\n",
        "    print('%s: %.5f' % (a, f1_score(labels[:, i], preds[:, i])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouCZUdkeaIYm"
      },
      "source": [
        "#Predict attributes on our tiktok dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilf_GCm-2CrI"
      },
      "outputs": [],
      "source": [
        "def _parse_function(example_proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature((), tf.string),\n",
        "        'user': tf.io.FixedLenFeature((), tf.string),\n",
        "        'label': tf.io.FixedLenFeature((), tf.float32),\n",
        "\n",
        "    }\n",
        "\n",
        "    data = tf.io.parse_single_example(example_proto, feature_description)\n",
        "    image = data['image']\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize_with_pad(image, 128, 128) #resize images to fit model input\n",
        "    image = tf.cast(image, tf.float32) / 255.0 # Normalize the values of the image from the range [0, 255] \n",
        "\n",
        "    return {'image': image, 'user': data['user']}, data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "humyPdcI2kfA"
      },
      "outputs": [],
      "source": [
        "# Dataset, 32 face per channel, random-shuffled.\n",
        "tiktok_dataset = tf.data.Dataset.from_tensor_slices(['/content/drive/MyDrive/tiktok_model/tiktok_dataset.tfrecord'])\n",
        "tiktok_dataset = tiktok_dataset.flat_map(lambda filename: tf.data.TFRecordDataset(filename))\n",
        "tiktok_dataset = tiktok_dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "tiktok_dataset = tiktok_dataset.shuffle(1234).batch(64, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA35-Rgh06nL"
      },
      "outputs": [],
      "source": [
        "#example\n",
        "labels = []\n",
        "preds = []\n",
        "images =[]\n",
        "\n",
        "for e, l in tiktok_dataset.take(1):\n",
        "    labels.extend(l.numpy())\n",
        "    preds.extend(model.predict(e['image'], verbose=False))\n",
        "    images.extend(e['image'].numpy())\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jImHcqn1uKF"
      },
      "outputs": [],
      "source": [
        "plt.imshow(images[1])\n",
        "z = dict(zip(ATTRIBUTES, preds[1].numpy()))\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wocx3NPgHToB"
      },
      "outputs": [],
      "source": [
        "#Predict tikok dataset attributes\n",
        "labels = []\n",
        "preds = []\n",
        "users = []\n",
        "\n",
        "for e, l in tiktok_dataset:\n",
        "    labels.extend(l.numpy())\n",
        "    users.extend(e['user'].numpy())\n",
        "    preds.extend(model.predict(e['image'], verbose=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ixt8NpNV7E4"
      },
      "outputs": [],
      "source": [
        "#convert to array\n",
        "labels = np.array(labels)\n",
        "preds = np.array(preds)\n",
        "preds_binary = np.array(preds_binary)\n",
        "users = np.array(users)\n",
        "\n",
        "#create dataframes\n",
        "df = pd.DataFrame(\n",
        "    {'username': users,\n",
        "     'engagement': labels\n",
        "     }\n",
        "     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKdVEvfZoclC"
      },
      "outputs": [],
      "source": [
        "df[ATTRIBUTES] = pd.DataFrame(preds, index=df.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI-hMXcdhuWG"
      },
      "source": [
        "# Regression Descision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fdIdKDDTmxr"
      },
      "outputs": [],
      "source": [
        "X, y = df[ATTRIBUTES], df['engagement']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6avqUTmuFymm"
      },
      "outputs": [],
      "source": [
        "X_train_split, X_eval_split, y_train_split, y_eval_split = train_test_split(X_train, y_train, test_size=0.2, random_state=22)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####LightGBM"
      ],
      "metadata": {
        "id": "7Wqqui90Wbxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = lgb.LGBMRegressor()"
      ],
      "metadata": {
        "id": "O9Yvon9oWnu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_split, y_train_split, eval_set=(X_eval_split, y_eval_split), verbose=False, categorical_feature=ATTRIBUTES)"
      ],
      "metadata": {
        "id": "34VR5bA8Wvcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlpA67y-Xmlh"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkuGs5jQXmlo"
      },
      "outputs": [],
      "source": [
        "print(\"MAE: \", mean_absolute_error(y_test, preds))\n",
        "print(\"MAPE: \", mean_absolute_percentage_error(y_test, preds))\n",
        "print(\"MSE: \", mean_squared_error(y_test, preds))\n",
        "print(\"RMSE: \", mean_squared_error(y_test, preds, squared=False))\n",
        "\n",
        "#calculate Pearson correlation\n",
        "print(\"Pearson :\", np.corrcoef(preds, y_test)[0][1])\n",
        "\n",
        "#Spearman correlation\n",
        "res, p_value = stats.spearmanr(preds, y_test)\n",
        "print(\"Spearman :\", res, p_value)\n",
        "\n",
        "\n",
        "#adjusted r2\n",
        "n_predictors = 40\n",
        "print(\"Adj. R2: \",adjusted_r2(y_test, preds, n_predictors))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.jointplot(x=y_test, y=preds, alpha=0.3, s=3)\n",
        "plt.xlabel('Ground Truth [%]')\n",
        "plt.ylabel('Predictions [%]')"
      ],
      "metadata": {
        "id": "7KyDfpyBds2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyZJGsa-iae4"
      },
      "source": [
        "####CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLYLEZGQiO-6"
      },
      "outputs": [],
      "source": [
        "catboostmodel = CatBoostRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-ZouJE0F4Wo"
      },
      "outputs": [],
      "source": [
        "catboostmodel.fit(X_train_split, y_train_split, eval_set=(X_eval_split, y_eval_split), use_best_model=True, verbose=False, cat_features=ATTRIBUTES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12x4HuiKi5Nt"
      },
      "outputs": [],
      "source": [
        "preds = catboostmodel.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DPhJtPPi8tf"
      },
      "outputs": [],
      "source": [
        "print(\"MAE: \", mean_absolute_error(y_test, preds))\n",
        "print(\"MAPE: \", mean_absolute_percentage_error(y_test, preds))\n",
        "print(\"MSE: \", mean_squared_error(y_test, preds))\n",
        "print(\"RMSE: \", mean_squared_error(y_test, preds, squared=False))\n",
        "\n",
        "#calculate pearson correlation\n",
        "print(\"Pearson :\", np.corrcoef(preds, y_test)[0][1])\n",
        "\n",
        "#Spearman correlation\n",
        "res, p_value = stats.spearmanr(preds, y_test)\n",
        "print(\"Spearman :\", res, p_value)\n",
        "\n",
        "\n",
        "#adjusted r2\n",
        "n_predictors = 40\n",
        "print(\"Adj. R2: \",adjusted_r2(y_test, preds, n_predictors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzG8F641GGuJ"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x=y_test, y=preds, alpha=0.3, s=3)\n",
        "plt.xlabel('Ground Truth [%]')\n",
        "plt.ylabel('Predictions [%]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMbBtC7ME8YC"
      },
      "source": [
        "#####SHAP analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMP4_YcRFBwF"
      },
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(catboostmodel)\n",
        "shap_values = explainer(pd.DataFrame(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZAhN6G3IJ91"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values, max_display=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT-uuwcZGUnt"
      },
      "outputs": [],
      "source": [
        "shap.plots.beeswarm(shap_values, max_display=40, color=newCmap)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}